{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/ml2022spring-hw3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((128, 128), scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.RandomAffine(30),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self,path=None,tfm=test_tfm,files=None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        if path:\n",
    "            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        else:\n",
    "            self.files = files\n",
    "        self.transform = tfm\n",
    "        print('Num of element: ', len(self.files))\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1\n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self, ic, oc, stride=1):\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(ic, oc, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(oc),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(oc, oc, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(oc),\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "        self.downsample = None\n",
    "        if stride != 1 or (ic != oc):\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(oc),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "        \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, block, num_layers, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.preconv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.layer0 = self.make_residual(block, 32, 64,  num_layers[0], stride=2)\n",
    "        self.layer1 = self.make_residual(block, 64, 128, num_layers[1], stride=2)\n",
    "        self.layer2 = self.make_residual(block, 128, 256, num_layers[2], stride=2)\n",
    "        self.layer3 = self.make_residual(block, 256, 512, num_layers[3], stride=2)\n",
    "        \n",
    "        #self.avgpool = nn.AvgPool2d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(            \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512*4*4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 11),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def make_residual(self, block, ic, oc, num_layer, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(ic, oc, stride))\n",
    "        for i in range(1, num_layer):\n",
    "            layers.append(block(oc, oc))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # [3, 128, 128]\n",
    "        out = self.preconv(x)  # [32, 64, 64]\n",
    "        out = self.layer0(out) # [64, 32, 32]\n",
    "        out = self.layer1(out) # [128, 16, 16]\n",
    "        out = self.layer2(out) # [256, 8, 8]\n",
    "        out = self.layer3(out) # [512, 4, 4]\n",
    "        #out = self.avgpool(out) # [512, 2, 2]\n",
    "        out = self.fc(out.view(out.size(0), -1)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "        super().__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = Variable(torch.ones(class_num, 1))\n",
    "        else:\n",
    "            if isinstance(alpha, Variable):\n",
    "                self.alpha = alpha\n",
    "            else:\n",
    "                self.alpha = Variable(alpha)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "        \n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        alpha = self.alpha[ids.data.view(-1)]\n",
    "        probs = (P*class_mask).sum(1).view(-1, 1)\n",
    "        \n",
    "        log_p = probs.log()\n",
    "        \n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p\n",
    "        \n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "class MyCrossEntropy(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_layers = [2, 4, 3, 1] # residual number layers\n",
    "alpha = torch.Tensor([1, 2.3, 0.66, 1, 1.1, 0.75, 2.3, 3.5, 1.1, 0.66, 1.4])\n",
    "\n",
    "n_epochs = 300\n",
    "patience = 32 # If no improvement in 'patience' epochs, early stop\n",
    "\n",
    "k_fold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './data/training'\n",
    "val_dir = './data/validation'\n",
    "\n",
    "train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\n",
    "val_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\n",
    "total_files = train_files + val_files\n",
    "random.shuffle(total_files)\n",
    "\n",
    "num = len(total_files) // k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "test_fold = k_fold\n",
    "\n",
    "for i in range(test_fold):\n",
    "    fold = i+1\n",
    "    print(f'\\n\\nStarting Fold: {fold} ********************************************')\n",
    "    model = Classifier(Residual_Block, num_layers).to(device)\n",
    "    criterion = FocalLoss(11, alpha=alpha)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0004, weight_decay=2e-5) \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=16, T_mult=1)\n",
    "    stale = 0\n",
    "    best_acc = 0\n",
    "    \n",
    "    val_data = total_files[i*num: (i+1)*num]\n",
    "    train_data = total_files[:i*num] + total_files[(i+1)*num:]\n",
    "    \n",
    "    train_set = FoodDataset(tfm=train_tfm, files=train_data)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    valid_set = FoodDataset(tfm=test_tfm, files=val_data)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "        # ---------- Training ----------\n",
    "        # Make sure the model is in train mode before training.\n",
    "        model.train()\n",
    "    \n",
    "        # These are used to record information in training.\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        \n",
    "        pbar = tqdm(train_loader)\n",
    "        pbar.set_description(f'T: {epoch+1:03d}/{n_epochs:03d}')\n",
    "        for batch in pbar:\n",
    "    \n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "            #print(imgs.shape,labels.shape)\n",
    "    \n",
    "            # Forward the data. (Make sure data and model are on the same device.)\n",
    "            logits = model(imgs.to(device))\n",
    "    \n",
    "            # Calculate the cross-entropy loss.\n",
    "            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "    \n",
    "            # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Compute the gradients for parameters.\n",
    "            loss.backward()\n",
    "    \n",
    "            # Clip the gradient norms for stable training.\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    \n",
    "            # Update the parameters with computed gradients.\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute the accuracy for current batch.\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "    \n",
    "            # Record the loss and accuracy.\n",
    "            train_loss.append(loss.item())\n",
    "            train_accs.append(acc)\n",
    "            pbar.set_postfix({'lr':lr, 'b_loss':loss.item(), 'b_acc':acc.item(),\n",
    "                    'loss':sum(train_loss)/len(train_loss), 'acc': sum(train_accs).item()/len(train_accs)})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "        model.eval()\n",
    "    \n",
    "        # These are used to record information in validation.\n",
    "        valid_loss = []\n",
    "        valid_accs = []\n",
    "    \n",
    "        # Iterate the validation set by batches.\n",
    "        pbar = tqdm(valid_loader)\n",
    "        pbar.set_description(f'V: {epoch+1:03d}/{n_epochs:03d}')\n",
    "        for batch in pbar:\n",
    "\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "    \n",
    "            # We don't need gradient in validation.\n",
    "            # Using torch.no_grad() accelerates the forward process.\n",
    "            with torch.no_grad():\n",
    "                logits = model(imgs.to(device))\n",
    "    \n",
    "            # We can still compute the loss (but not the gradient).\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "    \n",
    "            # Compute the accuracy for current batch.\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "    \n",
    "            # Record the loss and accuracy.\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_accs.append(acc)\n",
    "            pbar.set_postfix({'v_loss':sum(valid_loss)/len(valid_loss), \n",
    "                              'v_acc': sum(valid_accs).item()/len(valid_accs)})\n",
    "        \n",
    "            #break\n",
    "    \n",
    "        # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "        valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "        valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    \n",
    "    \n",
    "        if valid_acc > best_acc:\n",
    "            print(f\"Best model found at fold {fold} epoch {epoch+1}, acc={valid_acc:.5f}, saving model\")\n",
    "            torch.save(model.state_dict(), f\"Fold_{fold}_best.ckpt\")\n",
    "            # only save best to prevent output memory exceed error\n",
    "            best_acc = valid_acc\n",
    "            stale = 0\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale > patience:\n",
    "                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"ml2022spring-hw3b/food11/test\"\n",
    "test_set = FoodDataset(test_dir, tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './data/test'\n",
    "test_loaders = []\n",
    "for i in range(5):\n",
    "    test_set_i = FoodDataset(test_dir, tfm=train_tfm)\n",
    "    test_loader_i = DataLoader(test_set_i, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loaders.append(test_loader_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "models = []\n",
    "for i in range(0, 4):\n",
    "    fold = i + 1\n",
    "    model_best = Classifier(Residual_Block, num_layers).to(device)\n",
    "    model_best.load_state_dict(torch.load(f\"Fold_{fold}_best.ckpt\"))\n",
    "    model_best.eval()\n",
    "    models.append(model_best)\n",
    "\n",
    "preds = [[], [], [], [], [], []] \n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        batch_preds = [] \n",
    "        for model_best in models:\n",
    "            batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "        batch_preds = sum(batch_preds)\n",
    "        preds[0].extend(batch_preds.squeeze().tolist())\n",
    "        \n",
    "        #batch_label = np.argmax(batch_preds, axis=1)\n",
    "        #prediction += batch_label.squeeze().tolist()\n",
    "        \n",
    "    for i, loader in enumerate(test_loaders):\n",
    "        for data, _ in loader:\n",
    "            batch_preds = []\n",
    "            for model_best in models:\n",
    "                batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "            batch_preds = sum(batch_preds)\n",
    "            preds[i+1].extend(batch_preds.squeeze().tolist())\n",
    "\n",
    "preds = np.array(preds)\n",
    "print(preds.shape)\n",
    "preds = 0.6* preds[0] + 0.1 * preds[1] + 0.1 * preds[2] + 0.1 * preds[3] + 0.1 * preds[4] + 0.1 * preds[5]\n",
    "print(preds.shape)\n",
    "prediction = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test csv\n",
    "import pandas as pd\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e74e791fac79cd95acd8863fe3f7e8927d9df23efc816f2087cf9e199b41ecb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
